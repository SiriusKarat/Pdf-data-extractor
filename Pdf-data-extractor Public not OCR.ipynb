{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c3f34-ad35-4b02-bb34-30536882be43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#–í–µ—Ä—Å–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–æ–≤ –±–µ–∑ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è OCR –≤ —Å–∫—Ä–∏–ø—Ç–µ.\n",
    "#–û—Ç—Å—É—Ç—Å–≤—É–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É—Å—Ç–∞–Ω–æ–≤–∫–∏ Tesseract –∏ Poppler. \n",
    "#–†–∞—Å–ø–æ–∑–Ω–æ–≤–∞–Ω–∏–µ pdf —Å–∫–∞–Ω–æ–≤ –¥–µ–ª–∞–µ–º —á–µ—Ä–µ–∑ OCR —É—Ç–∏–ª–∏—Ç—É.\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import os\n",
    "\n",
    "def analyze_pdf_type(pdf_path):\n",
    "    \"\"\"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–∏–ø PDF —Ñ–∞–π–ª–∞\"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        page = doc[0]  # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞\n",
    "\n",
    "        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç\n",
    "        text = page.get_text()\n",
    "\n",
    "        # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤\n",
    "        text_length = len(text.strip())\n",
    "\n",
    "        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "        images = page.get_images()\n",
    "        image_count = len(images)\n",
    "\n",
    "        doc.close()\n",
    "\n",
    "        print(f\"üìä –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {os.path.basename(pdf_path)}\")\n",
    "        print(f\"   –°–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞: {text_length}\")\n",
    "        print(f\"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {image_count}\")\n",
    "\n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø\n",
    "        if text_length < 50 and image_count > 0:\n",
    "            return \"scan\", text  # –°–∫–∞–Ω\n",
    "        elif text_length >= 50:\n",
    "            return \"text\", text  # –¢–µ–∫—Å—Ç–æ–≤—ã–π PDF\n",
    "        else:\n",
    "            return \"empty\", text  # –ü—É—Å—Ç–æ–π/–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π\n",
    "\n",
    "    except Exception as e:\n",
    "        return \"error\", str(e)\n",
    "\n",
    "def extract_data_from_text_pdf(text):\n",
    "    \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ PDF\"\"\"\n",
    "    try:\n",
    "        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–¥\n",
    "        year_match = re.search(r'(\\d{4})\\s*–≥\\.', text)\n",
    "        year = year_match.group(1) if year_match else \"–ù–µ –Ω–∞–π–¥–µ–Ω\"\n",
    "\n",
    "        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ—Ä–æ–¥\n",
    "        city = \"–ù–µ –Ω–∞–π–¥–µ–Ω\"\n",
    "        city_patterns = [\n",
    "            r'([–ê-–Ø][–∞-—è—ë]+)\\s+\\d{4}\\s*–≥\\.',\n",
    "            r'–≥\\.\\s*([–ê-–Ø][–∞-—è—ë]+)',\n",
    "            r'([–ê-–Ø][–∞-—è—ë]+),?\\s+\\d{4}',\n",
    "            r'^([–ê-–Ø][–∞-—è—ë]+)\\s'\n",
    "        ]\n",
    "\n",
    "        for pattern in city_patterns:\n",
    "            city_match = re.search(pattern, text)\n",
    "            if city_match:\n",
    "                city = city_match.group(1)\n",
    "                if city.lower() not in ['–≥', '—É–ª', '–¥', '—Ä–µ—Å–ø—É–±–ª–∏–∫–∞', '–æ–±–ª–∞—Å—Ç—å']:\n",
    "                    break\n",
    "\n",
    "        if city == \"–ù–µ –Ω–∞–π–¥–µ–Ω\":\n",
    "            city_match = re.search(r'(–ò—Ä–∫—É—Ç—Å–∫|–ú–æ—Å–∫–≤–∞|–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥|[–ê-–Ø][–∞-—è—ë]{3,})', text)\n",
    "            if city_match:\n",
    "                city = city_match.group(1)\n",
    "\n",
    "        # –ò–∑–≤–ª–µ–∫–∞–µ–º –í–°–ü ‚Ññ\n",
    "        vsp_patterns = [\n",
    "            r'[–û–æ]—Ñ–∏—Å\\s*[‚Ññ#]?\\s*([0-9/\\s]+)',\n",
    "            r'[–í–≤][–°—Å][–ü–ø]\\s*[‚Ññ#]?\\s*([0-9/\\s\\-]+)',\n",
    "            r'(\\d{4}/\\d\\s*\\d{2})'\n",
    "        ]\n",
    "\n",
    "        vsp = \"–ù–µ –Ω–∞–π–¥–µ–Ω\"\n",
    "        for pattern in vsp_patterns:\n",
    "            vsp_match = re.search(pattern, text)\n",
    "            if vsp_match:\n",
    "                vsp = vsp_match.group(1).strip()\n",
    "                vsp = re.sub(r'\\s+', ' ', vsp)\n",
    "                break\n",
    "\n",
    "        return {\n",
    "            'year': year,\n",
    "            'city': city,\n",
    "            'vsp': vsp,\n",
    "            'success': True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'success': False\n",
    "        }\n",
    "\n",
    "def process_all_pdfs_in_folder(folder_path):\n",
    "    \"\"\"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ PDF —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ç–∏–ø–∞\"\"\"\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø–∞–ø–∫–∞\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder_path}\")\n",
    "        return []\n",
    "\n",
    "    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö PDF —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.pdf')]\n",
    "\n",
    "    if not pdf_files:\n",
    "        print(\"‚ùå PDF —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ\")\n",
    "        return []\n",
    "\n",
    "    print(f\"‚úÖ –ù–∞–π–¥–µ–Ω–æ PDF —Ñ–∞–π–ª–æ–≤: {len(pdf_files)}\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π PDF —Ñ–∞–π–ª\n",
    "    for i, pdf_file in enumerate(pdf_files, 1):\n",
    "        full_path = os.path.join(folder_path, pdf_file)\n",
    "        print(f\"üìÑ [{i}/{len(pdf_files)}] –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {pdf_file}\")\n",
    "\n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø PDF\n",
    "        pdf_type, content = analyze_pdf_type(full_path)\n",
    "\n",
    "        result = {\n",
    "            'file': pdf_file,\n",
    "            'type': pdf_type\n",
    "        }\n",
    "\n",
    "        if pdf_type == \"text\":\n",
    "            # –¢–µ–∫—Å—Ç–æ–≤—ã–π PDF - –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "            data = extract_data_from_text_pdf(content)\n",
    "            result.update(data)\n",
    "            print(f\"   ‚úÖ –¢–µ–∫—Å—Ç–æ–≤—ã–π PDF\")\n",
    "            print(f\"   üèôÔ∏è  –ì–æ—Ä–æ–¥: {data.get('city', '–ù–µ –Ω–∞–π–¥–µ–Ω')}\")\n",
    "            print(f\"   üìÖ  –ì–æ–¥: {data.get('year', '–ù–µ –Ω–∞–π–¥–µ–Ω')}\")\n",
    "            print(f\"   üè¢  –í–°–ü ‚Ññ: {data.get('vsp', '–ù–µ –Ω–∞–π–¥–µ–Ω')}\")\n",
    "\n",
    "        elif pdf_type == \"scan\":\n",
    "            # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π PDF - —Å–æ–æ–±—â–∞–µ–º, —á—Ç–æ –Ω—É–∂–µ–Ω OCR\n",
    "            result.update({\n",
    "                'error': '–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π PDF - –Ω—É–∂–µ–Ω OCR (Poppler –∏ Tesseract)',\n",
    "                'success': False\n",
    "            })\n",
    "            print(f\"   ‚ö†Ô∏è  –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π PDF (–∫–∞—Ä—Ç–∏–Ω–∫–∞)\")\n",
    "            print(f\"   üìã –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω—É–∂–µ–Ω OCR:\")\n",
    "            print(f\"      1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Poppler –∏ Tesseract\")\n",
    "            print(f\"      2. –ò–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ Google Drive ‚Üí Google Docs\")\n",
    "            print(f\"      3. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–Ω–ª–∞–π–Ω OCR —Å–µ—Ä–≤–∏—Å—ã\")\n",
    "\n",
    "        elif pdf_type == \"empty\":\n",
    "            result.update({\n",
    "                'error': '–ü—É—Å—Ç–æ–π –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π PDF',\n",
    "                'success': False\n",
    "            })\n",
    "            print(f\"   ‚ùå –ü—É—Å—Ç–æ–π –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π PDF\")\n",
    "\n",
    "        else:  # error\n",
    "            result.update({\n",
    "                'error': content,\n",
    "                'success': False\n",
    "            })\n",
    "            print(f\"   ‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {content}\")\n",
    "\n",
    "        results.append(result)\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "    # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É\n",
    "    print(\"üìä –°–í–û–î–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê:\")\n",
    "    print(\"=\" * 120)\n",
    "    print(f\"{'‚Ññ':<3} {'–§–∞–π–ª':<35} {'–¢–∏–ø':<15} {'–ì–æ—Ä–æ–¥':<15} {'–ì–æ–¥':<6} {'–í–°–ü ‚Ññ':<15} {'–°—Ç–∞—Ç—É—Å':<20}\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "    for i, result in enumerate(results, 1):\n",
    "        file_type = result.get('type', 'error')\n",
    "        status = \"‚úÖ\" if result.get('success') else \"‚ùå\"\n",
    "\n",
    "        if file_type == \"text\" and result.get('success'):\n",
    "            print(f\"{i:<3} {result['file'][:34]:<35} {'–¢–µ–∫—Å—Ç–æ–≤—ã–π':<15} {result.get('city', ''):<15} {result.get('year', ''):<6} {result.get('vsp', ''):<15} {status:<20}\")\n",
    "        elif file_type == \"scan\":\n",
    "            print(f\"{i:<3} {result['file'][:34]:<35} {'–°–∫–∞–Ω':<15} {'':<15} {'':<6} {'':<15} {'‚ö†Ô∏è OCR –Ω—É–∂–µ–Ω':<20}\")\n",
    "        else:\n",
    "            print(f\"{i:<3} {result['file'][:34]:<35} {file_type:<15} {'':<15} {'':<6} {'':<15} {'‚ùå –û—à–∏–±–∫–∞':<20}\")\n",
    "\n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "    text_count = sum(1 for r in results if r.get('type') == 'text')\n",
    "    scan_count = sum(1 for r in results if r.get('type') == 'scan')\n",
    "    error_count = sum(1 for r in results if r.get('type') in ['error', 'empty'])\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(f\"üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\")\n",
    "    print(f\"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(results)}\")\n",
    "    print(f\"   –¢–µ–∫—Å—Ç–æ–≤—ã–µ PDF: {text_count}\")\n",
    "    print(f\"   –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ PDF: {scan_count}\")\n",
    "    print(f\"   –° –æ—à–∏–±–∫–∞–º–∏: {error_count}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ\n",
    "folder_path = r'C:\\Users\\–ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å PDF —Ñ–∞–π–ª–∞–º–∏'\n",
    "results = process_all_pdfs_in_folder(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
